global:
  scrape_interval: 15s # How frequently to scrape targets.
  evaluation_interval: 15s # How frequently to evaluate rules.

# Add the remote_write configuration here
remote_write:
  - url: "PLACEHOLDER_GRAFANA_REMOTE_WRITE_URL" # Placeholder for Grafana Cloud Remote Write URL
    basic_auth:
      username: "PLACEHOLDER_GRAFANA_USERNAME" # Placeholder for Grafana Cloud Username/Instance ID
      password: "PLACEHOLDER_GRAFANA_API_KEY" # Placeholder for Grafana Cloud API Key

scrape_configs:
  - job_name: 'remote-log-service' # Renamed for clarity, was 'log-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['ec2-54-208-131-6.compute-1.amazonaws.com:8080'] # Target the remote log-service EC2

  - job_name: 'local-node-exporter' # Renamed for clarity, was 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100'] # This targets the node-exporter on the monitoring EC2 via Docker network

  - job_name: 'remote-log-service-node-exporter' # New job for node-exporter on the log-service EC2
    static_configs:
      - targets: ['ec2-54-208-131-6.compute-1.amazonaws.com:9100'] # Target node-exporter on the remote log-service EC2

  # To monitor other microservices, add similar job configurations here:
  # - job_name: 'another-service'
  #   metrics_path: '/actuator/prometheus'
  #   static_configs:
  #     - targets: ['another-service:port']
